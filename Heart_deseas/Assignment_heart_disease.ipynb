{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Liberaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# To preprocess the data\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "# import iterative imputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# machine learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "#for classification tasks\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier\n",
    "#metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ignore warnings   \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>typical angina</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>150.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.3</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed defect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>108.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>flat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>129.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.6</td>\n",
       "      <td>flat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable defect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>non-anginal</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>187.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>172.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.4</td>\n",
       "      <td>upsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age     sex    dataset               cp  trestbps   chol    fbs  \\\n",
       "0   1   63    Male  Cleveland   typical angina     145.0  233.0   True   \n",
       "1   2   67    Male  Cleveland     asymptomatic     160.0  286.0  False   \n",
       "2   3   67    Male  Cleveland     asymptomatic     120.0  229.0  False   \n",
       "3   4   37    Male  Cleveland      non-anginal     130.0  250.0  False   \n",
       "4   5   41  Female  Cleveland  atypical angina     130.0  204.0  False   \n",
       "\n",
       "          restecg  thalch  exang  oldpeak        slope   ca  \\\n",
       "0  lv hypertrophy   150.0  False      2.3  downsloping  0.0   \n",
       "1  lv hypertrophy   108.0   True      1.5         flat  3.0   \n",
       "2  lv hypertrophy   129.0   True      2.6         flat  2.0   \n",
       "3          normal   187.0  False      3.5  downsloping  0.0   \n",
       "4  lv hypertrophy   172.0  False      1.4    upsloping  0.0   \n",
       "\n",
       "                thal  num  \n",
       "0       fixed defect    0  \n",
       "1             normal    2  \n",
       "2  reversable defect    1  \n",
       "3             normal    0  \n",
       "4             normal    0  "
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "df=pd.read_csv('heart_disease_uci.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 16)"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ca          66.413043\n",
       "thal        52.826087\n",
       "slope       33.586957\n",
       "fbs          9.782609\n",
       "oldpeak      6.739130\n",
       "trestbps     6.413043\n",
       "thalch       5.978261\n",
       "exang        5.978261\n",
       "chol         3.260870\n",
       "restecg      0.217391\n",
       "id           0.000000\n",
       "age          0.000000\n",
       "sex          0.000000\n",
       "dataset      0.000000\n",
       "cp           0.000000\n",
       "num          0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.isnull().sum()/len(df)*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trestbps',\n",
       " 'chol',\n",
       " 'fbs',\n",
       " 'restecg',\n",
       " 'thalch',\n",
       " 'exang',\n",
       " 'oldpeak',\n",
       " 'slope',\n",
       " 'ca',\n",
       " 'thal']"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()[df.isnull().sum() > 0].sort_values(ascending=False)\n",
    "missing_data_cols = df.isnull().sum()[df.isnull().sum() > 0].index.tolist()\n",
    "missing_data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['thal', 'ca', 'slope', 'exang', 'restecg','fbs', 'cp', 'sex', 'num']\n",
    "bool_cols = ['fbs', 'exang']\n",
    "numeric_cols = ['oldpeak', 'thalch', 'chol', 'trestbps', 'age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function to impute the missing values in thal column\n",
    "\n",
    "def impute_categorical_missing_data(passed_col):\n",
    "    \n",
    "    df_null = df[df[passed_col].isnull()]\n",
    "    df_not_null = df[df[passed_col].notnull()]\n",
    "\n",
    "    X = df_not_null.drop(passed_col, axis=1)\n",
    "    y = df_not_null[passed_col]\n",
    "    \n",
    "    other_missing_cols = [col for col in missing_data_cols if col != passed_col]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'object' or X[col].dtype == 'category':\n",
    "            X[col] = label_encoder.fit_transform(X[col])\n",
    "\n",
    "    if passed_col in bool_cols:\n",
    "        y = label_encoder.fit_transform(y)\n",
    "        \n",
    "    iterative_imputer = IterativeImputer(estimator=RandomForestRegressor(random_state=42), add_indicator=True)\n",
    "\n",
    "    for col in other_missing_cols:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            col_with_missing_values = X[col].values.reshape(-1, 1)\n",
    "            imputed_values = iterative_imputer.fit_transform(col_with_missing_values)\n",
    "            X[col] = imputed_values[:, 0]\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(\"The feature '\"+ passed_col+ \"' has been imputed with\", round((acc_score * 100), 2), \"accuracy\\n\")\n",
    "\n",
    "    X = df_null.drop(passed_col, axis=1)\n",
    "\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'object' or X[col].dtype == 'category':\n",
    "            X[col] = label_encoder.fit_transform(X[col])\n",
    "\n",
    "    for col in other_missing_cols:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            col_with_missing_values = X[col].values.reshape(-1, 1)\n",
    "            imputed_values = iterative_imputer.fit_transform(col_with_missing_values)\n",
    "            X[col] = imputed_values[:, 0]\n",
    "        else:\n",
    "            pass\n",
    "                \n",
    "    if len(df_null) > 0: \n",
    "        df_null[passed_col] = rf_classifier.predict(X)\n",
    "        if passed_col in bool_cols:\n",
    "            df_null[passed_col] = df_null[passed_col].map({0: False, 1: True})\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    df_combined = pd.concat([df_not_null, df_null])\n",
    "    \n",
    "    return df_combined[passed_col]\n",
    "\n",
    "def impute_continuous_missing_data(passed_col):\n",
    "    \n",
    "    df_null = df[df[passed_col].isnull()]\n",
    "    df_not_null = df[df[passed_col].notnull()]\n",
    "    X = df_not_null.drop(passed_col, axis=1)\n",
    "    y = df_not_null[passed_col]\n",
    "    \n",
    "    other_missing_cols = [col for col in missing_data_cols if col != passed_col]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'object' or X[col].dtype == 'category':\n",
    "            X[col] = label_encoder.fit_transform(X[col])\n",
    "    \n",
    "    iterative_imputer = IterativeImputer(estimator=RandomForestRegressor(random_state=42), add_indicator=True)\n",
    "\n",
    "    for col in other_missing_cols:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            col_with_missing_values = X[col].values.reshape(-1, 1)\n",
    "            imputed_values = iterative_imputer.fit_transform(col_with_missing_values)\n",
    "            X[col] = imputed_values[:, 0]\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    rf_regressor = RandomForestRegressor()\n",
    "\n",
    "    rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "    print(\"MAE =\", mean_absolute_error(y_test, y_pred), \"\\n\")\n",
    "    print(\"RMSE =\", mean_squared_error(y_test, y_pred, squared=False), \"\\n\")\n",
    "    print(\"R2 =\", r2_score(y_test, y_pred), \"\\n\")\n",
    "\n",
    "    X = df_null.drop(passed_col, axis=1)\n",
    "\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'object' or X[col].dtype == 'category':\n",
    "            X[col] = label_encoder.fit_transform(X[col])\n",
    "    for col in other_missing_cols:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            col_with_missing_values = X[col].values.reshape(-1, 1)\n",
    "            imputed_values = iterative_imputer.fit_transform(col_with_missing_values)\n",
    "            X[col] = imputed_values[:, 0]\n",
    "        else:\n",
    "            pass\n",
    "                \n",
    "    if len(df_null) > 0: \n",
    "        df_null[passed_col] = rf_regressor.predict(X)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    df_combined = pd.concat([df_not_null, df_null])\n",
    "    \n",
    "    return df_combined[passed_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values trestbps : 6.41%\n",
      "MAE = 13.248265895953756 \n",
      "\n",
      "RMSE = 17.226749346977325 \n",
      "\n",
      "R2 = 0.07341670427558655 \n",
      "\n",
      "Missing Values chol : 3.26%\n",
      "MAE = 45.25028089887641 \n",
      "\n",
      "RMSE = 64.31429764415276 \n",
      "\n",
      "R2 = 0.6723322432525373 \n",
      "\n",
      "Missing Values fbs : 9.78%\n",
      "The feature 'fbs' has been imputed with 78.92 accuracy\n",
      "\n",
      "Missing Values restecg : 0.22%\n",
      "The feature 'restecg' has been imputed with 64.13 accuracy\n",
      "\n",
      "Missing Values thalch : 5.98%\n",
      "MAE = 16.57843930635838 \n",
      "\n",
      "RMSE = 21.62706136387915 \n",
      "\n",
      "R2 = 0.31988189113045573 \n",
      "\n",
      "Missing Values exang : 5.98%\n",
      "The feature 'exang' has been imputed with 77.46 accuracy\n",
      "\n",
      "Missing Values oldpeak : 6.74%\n",
      "MAE = 0.5564941860465116 \n",
      "\n",
      "RMSE = 0.7790736784872326 \n",
      "\n",
      "R2 = 0.4217508419082805 \n",
      "\n",
      "Missing Values slope : 33.59%\n",
      "The feature 'slope' has been imputed with 65.04 accuracy\n",
      "\n",
      "Missing Values ca : 66.41%\n",
      "The feature 'ca' has been imputed with 64.52 accuracy\n",
      "\n",
      "Missing Values thal : 52.83%\n",
      "The feature 'thal' has been imputed with 71.26 accuracy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# impute missing values using our functions\n",
    "for col in missing_data_cols:\n",
    "    print(\"Missing Values\", col, \":\", str(round((df[col].isnull().sum() / len(df)) * 100, 2))+\"%\")\n",
    "    if col in categorical_cols:\n",
    "        df[col] = impute_categorical_missing_data(col)\n",
    "    elif col in numeric_cols:\n",
    "        df[col] = impute_continuous_missing_data(col)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "age         0\n",
       "sex         0\n",
       "dataset     0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalch      0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "num         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['restecg']=df['restecg'].fillna(df['restecg'].mode()[0])\n",
    "df['chol']=df['chol'].fillna(df['chol'].median())\n",
    "df['exang']=df['exang'].fillna(df['exang'].median())\n",
    "df['thalch']=df['thalch'].fillna(df['thalch'].median())\n",
    "df['trestbps']=df['trestbps'].fillna(df['trestbps'].median())\n",
    "df['oldpeak']=df['oldpeak'].fillna(df['oldpeak'].median())\n",
    "df['fbs']=df['fbs'].fillna(df['fbs'].median())\n",
    "df['ca'].isnull().sum()\n",
    "df['ca']=df['ca'].fillna(df['ca'].median())\n",
    "df['ca']=df['ca'].fillna(df['ca'].median())\n",
    "df['slope']=df['slope'].fillna(df['slope'].mode()[0])\n",
    "df['thal']=df['thal'].fillna(df['thal'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "age         0\n",
       "sex         0\n",
       "dataset     0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalch      0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "num         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('num',axis=1)\n",
    "y=df['num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the row from df where trestbps value is 0\n",
    "df[df['trestbps'] == 0]\n",
    "# remove this row from data\n",
    "df = df[df['trestbps'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "for col in x.columns:\n",
    "    if x[col].dtype=='object' or x[col].dtype=='category':\n",
    "        x[col]=le.fit_transform(x[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age  sex  dataset  cp  trestbps   chol  fbs  restecg  thalch  exang  \\\n",
       "0   1   63    1        0   3     145.0  233.0    1        0   150.0      0   \n",
       "1   2   67    1        0   0     160.0  286.0    0        0   108.0      1   \n",
       "2   3   67    1        0   0     120.0  229.0    0        0   129.0      1   \n",
       "3   4   37    1        0   2     130.0  250.0    0        1   187.0      0   \n",
       "4   5   41    0        0   1     130.0  204.0    0        0   172.0      0   \n",
       "\n",
       "   oldpeak  slope   ca  thal  \n",
       "0      2.3      0  0.0     0  \n",
       "1      1.5      1  3.0     1  \n",
       "2      2.6      1  2.0     2  \n",
       "3      3.5      0  0.0     1  \n",
       "4      1.4      2  0.0     1  "
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# from lightgbm import LGBMClassifier\n",
    "\n",
    "# impot pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Cross-validation Accuracy: 0.6290770362198934\n",
      "Test Accuracy: 0.657608695652174\n",
      "\n",
      "Model: Gradient Boosting\n",
      "Cross-validation Accuracy: 0.624995403566832\n",
      "Test Accuracy: 0.6413043478260869\n",
      "\n",
      "Model: Support Vector Machine\n",
      "Cross-validation Accuracy: 0.592388306674021\n",
      "Test Accuracy: 0.6141304347826086\n",
      "\n",
      "Model: Logistic Regression\n",
      "Cross-validation Accuracy: 0.520380584666299\n",
      "Test Accuracy: 0.5543478260869565\n",
      "\n",
      "Model: K-Nearest Neighbors\n",
      "Cross-validation Accuracy: 0.5556995771281485\n",
      "Test Accuracy: 0.6304347826086957\n",
      "\n",
      "Model: Decision Tree\n",
      "Cross-validation Accuracy: 0.5665839308696452\n",
      "Test Accuracy: 0.5815217391304348\n",
      "\n",
      "Model: Ada Boost\n",
      "Cross-validation Accuracy: 0.5964515535944107\n",
      "Test Accuracy: 0.5869565217391305\n",
      "\n",
      "Model: XG Boost\n",
      "Cross-validation Accuracy: 0.6222467365324509\n",
      "Test Accuracy: 0.6358695652173914\n",
      "\n",
      "Model: Naive Bayes\n",
      "Cross-validation Accuracy: 0.569277440706012\n",
      "Test Accuracy: 0.6195652173913043\n",
      "\n",
      "Best Model: Pipeline(steps=[('model', RandomForestClassifier(random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "# Create a list of models to evaluate\n",
    "models = [\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(random_state=42)),\n",
    "    ('Support Vector Machine', SVC(random_state=42)),\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42)),\n",
    "    ('K-Nearest Neighbors', KNeighborsClassifier()),\n",
    "    ('Decision Tree', DecisionTreeClassifier(random_state=42)),\n",
    "    ('Ada Boost', AdaBoostClassifier(random_state=42)),\n",
    "    ('XG Boost', XGBClassifier(random_state=42)),\n",
    "    ('Naive Bayes', GaussianNB())\n",
    "]\n",
    "\n",
    "best_model = None\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate over the models and evaluate their performance\n",
    "for name, model in models:\n",
    "    # Create a pipeline for each model\n",
    "    pipeline = Pipeline([\n",
    "        # ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        # ('encoder', OneHotEncoder(handle_unknown='ignore')),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(pipeline, x_train, y_train, cv=5)\n",
    "    \n",
    "    # Calculate mean accuracy\n",
    "    mean_accuracy = scores.mean()\n",
    "    \n",
    "    # Fit the pipeline on the training data\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = pipeline.predict(x_test)\n",
    "    \n",
    "    # Calculate accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    # Print the performance metrics\n",
    "    print(\"Model:\", name)\n",
    "    print(\"Cross-validation Accuracy:\", mean_accuracy)\n",
    "    print(\"Test Accuracy:\", accuracy)\n",
    "    print()\n",
    "    \n",
    "    # Check if the current model has the best accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = pipeline\n",
    "\n",
    "# Retrieve the best model\n",
    "print(\"Best Model:\", best_model)\n",
    "\n",
    "# save the best model\n",
    "#import pickle\n",
    "#pickle.dump(best_model, open('heart_disease_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Cross-validation Accuracy: 0.6820187534473249\n",
      "Test Accuracy: 0.6413043478260869\n",
      "\n",
      "Model: Gradient Boosting\n",
      "Cross-validation Accuracy: 0.6792792792792792\n",
      "Test Accuracy: 0.6304347826086957\n",
      "\n",
      "Model: Support Vector Machine\n",
      "Cross-validation Accuracy: 0.5977937120794264\n",
      "Test Accuracy: 0.5597826086956522\n",
      "\n",
      "Model: Logistic Regression\n",
      "Cross-validation Accuracy: 0.5162805662805663\n",
      "Test Accuracy: 0.4891304347826087\n",
      "\n",
      "Model: K-Nearest Neighbors\n",
      "Cross-validation Accuracy: 0.5991634491634492\n",
      "Test Accuracy: 0.5434782608695652\n",
      "\n",
      "Model: Decision Tree\n",
      "Cross-validation Accuracy: 0.620876999448428\n",
      "Test Accuracy: 0.6032608695652174\n",
      "\n",
      "Model: Ada Boost\n",
      "Cross-validation Accuracy: 0.5990990990990991\n",
      "Test Accuracy: 0.6032608695652174\n",
      "\n",
      "Model: XG Boost\n",
      "Cross-validation Accuracy: 0.656186799043942\n",
      "Test Accuracy: 0.6684782608695652\n",
      "\n",
      "Model: Naive Bayes\n",
      "Cross-validation Accuracy: 0.5638168781025924\n",
      "Test Accuracy: 0.5815217391304348\n",
      "\n",
      "Best Model: Pipeline(steps=[('model',\n",
      "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=None, device=None,\n",
      "                               early_stopping_rounds=None,\n",
      "                               enable_categorical=False, eval_metric=None,\n",
      "                               feature_types=None, gamma=None, grow_policy=None,\n",
      "                               importance_type=None,\n",
      "                               interaction_constraints=None, learning_rate=None,\n",
      "                               max_bin=None, max_cat_threshold=None,\n",
      "                               max_cat_to_onehot=None, max_delta_step=None,\n",
      "                               max_depth=None, max_leaves=None,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, multi_strategy=None,\n",
      "                               n_estimators=None, n_jobs=None,\n",
      "                               num_parallel_tree=None,\n",
      "                               objective='multi:softprob', ...))])\n"
     ]
    }
   ],
   "source": [
    "model = {\n",
    "    'Random Forest': (RandomForestClassifier(random_state=42),{'n_estimators': [10, 100, 1000], 'max_depth': [None, 5, 10]}),\n",
    "    'Gradient Boosting': (GradientBoostingClassifier(random_state=42),{'n_estimators': [10, 100]}),\n",
    "    'Support Vector Machine': (SVC(random_state=42),{'kernel': ['rbf', 'poly', 'sigmoid']}),\n",
    "    'Logistic Regression': (LogisticRegression(random_state=42),{}),\n",
    "    'K-Nearest Neighbors': (KNeighborsClassifier(),{'n_neighbors': np.arange(3, 100, 2)}),\n",
    "    'Decision Tree': (DecisionTreeClassifier(random_state=42),{'max_depth': [None, 5, 10], 'splitter': ['best', 'random']}),\n",
    "    'Ada Boost': (AdaBoostClassifier(random_state=42),{}),\n",
    "    'XG Boost': (XGBClassifier(random_state=42),{'n_estimators': [10, 100, 1000], 'learning_rate': [0.1, 0.01, 0.001]}),\n",
    "    'Naive Bayes': (GaussianNB(),{})\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate over the models and evaluate their performance\n",
    "for name, (model,params) in model.items():\n",
    "    # Create a pipeline for each model\n",
    "    pipeline = Pipeline([\n",
    "        # ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        # ('encoder', OneHotEncoder(handle_unknown='ignore')),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(pipeline, x_train, y_train, cv=5)\n",
    "    \n",
    "    # Calculate mean accuracy\n",
    "    mean_accuracy = scores.mean()\n",
    "    \n",
    "    # Fit the pipeline on the training data\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = pipeline.predict(x_test)\n",
    "\n",
    "    # Calculate accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    # Print the performance metrics\n",
    "    print(\"Model:\", name)\n",
    "    print(\"Cross-validation Accuracy:\", mean_accuracy)\n",
    "    print(\"Test Accuracy:\", accuracy)\n",
    "    print()\n",
    "    \n",
    "    # Check if the current model has the best accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = pipeline\n",
    "\n",
    "# Retrieve the best model\n",
    "print(\"Best Model:\", best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
